#!/home/detchar/opt/gwpysoft/bin/python
#
# Copyright (C) 2010  Tomoki Isogai
#
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 3 of the License, or (at your
# option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General
# Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.

"""
%prog --result_dir=DIRECTORY [options]

Tomoki Isogai (isogait@carleton.edu)

This program creates a report page of all channels analyzed and put link to each channel report page.
It lists veto candidate channels with the relevant values.

"""

import sys
import  os
import shutil
import time
import optparse
import ConfigParser
import re
import math
from numpy import array, sqrt, unique, arange, zeros, savetxt

try:
    import sqlite3
except ImportError:
    # pre 2.5.x
    from pysqlite2 import dbapi2 as sqlite3

import matplotlib
matplotlib.use('Agg')
from matplotlib.ticker import FormatStrFormatter,MultipleLocator,FixedLocator
import pylab
import matplotlib.pyplot as plt
from glue.segments import segment, segmentlist
from glue import segmentsUtils

from bcv import git_version
from bcv import bcvUtils

__author__ = "Tomoki Isogai <isogait@carleton.edu>"
__date__ = "1/5/2010"
__version__ = "1.0"
__prog__ = "veto_summaryPage"

def parse_commandline():
  """
  Parse the options given on the command-line.
  """
  parser = optparse.OptionParser(usage=__doc__,version=git_version.verbose_msg)
  parser.add_option("-r", "--result_dir",
                    help="Directory with result files from veto_report. Required.")
  parser.add_option("-i", "--ini_file",
                    help="Path to the .ini file used. Required.")
  parser.add_option("-H", "--HTriggerFile", default=None,
                    help="KW trigger file for channel H")
  parser.add_option("-o","--out_dir", default=".",
                    help="Output directory. (Default: current directory)")
  parser.add_option("-l","--scratch_dir",default=".",
                    help="Scratch directory to be used for database engine. Specify local scratch directory for better performance and less fileserver load. (Default: current directory)")
  parser.add_option("-v", "--verbose", action="store_true",
                    default=False, help="Run verbosely. (Default: None)")
  
  opts, args = parser.parse_args()
  
  ########################## sanity check ####################################
  
  # check if necessary input exists
  for o in ("result_dir","ini_file","HTriggerFile"):
    if getattr(opts,o) is None:
      parser.error("Error: --result_dir is a required parameter")
    if not os.path.exists(getattr(opts,o)):
      parser.error("Error: --%s not found."%o)

  ######################### show parameters ##################################
  if opts.verbose:
      print >> sys.stderr, ""
      print >> sys.stderr, "running %s..."%__prog__
      print >> sys.stderr, git_version.verbose_msg
      print >> sys.stderr, ""
      print >> sys.stderr, "*************** PARAMETERS **********************"
      for o in opts.__dict__.items():
        print >> sys.stderr, o[0]+":"
        print >> sys.stderr, o[1]
      print >> sys.stderr, ""
  
  return opts



# =============================================================================
#
#                             Webpage Generation Functions
#
# =============================================================================

def summary_page(channel_info,veto_segs, chan_name_list):
  """
  creates summary report page that links to each channel page
  """

  ############################## header ######################################
  title = "Bilinear Coupling Veto"
  
  # get UTC time for start and end time
  start_gps = channel_info[chan_name]["analysisStartTime"]
  end_gps = channel_info[chan_name]["analysisEndTime"]
  start_utc = os.popen('tconvert %s'%start_gps).readline()
  end_utc = os.popen('tconvert %s'%end_gps).readline()

  contents=["""
  <html>
  <head>
  <meta content="text/html; charset=ISO-8859-1"
  http-equiv="content-type">
  <title>%s</title>
  </head>
  <body>
  <div style="background-color:#C34A2C; color:black; padding:20px;">
  <big><big><big><big><b>%s (%s-%s)</b></big></big></big></big><br><br>
  <big><big>(%s - %s)</big></big></div>
  <br><br><br>
  """%(title,title,start_gps,end_gps,start_utc,end_utc)]

  ########################### histogram of H #################################

  # get veto segments
  if veto_segs.values() == []:
    deadTime_segs = segmentlist([])
    totalDeadTime = 0
  else:
    deadTime_segs = reduce(lambda x, y: x | y, veto_segs.values())
    totalDeadTime = abs(deadTime_segs)
  # Writing the total vetoed segments
  veto_seg_file = "%s/vetoed_segment.txt"%(baseDir)
  #file.write('Total Vetoed Segment = '+ repr(deadTime_segs) + '\n' )
  #file.close()
  deadTime_segs.coalesce()
  segmentsUtils.tosegwizard(open(veto_seg_file, 'w'), deadTime_segs)
   
# read in H triggers  
  Htrigs =  bcvUtils.textRead(opts.HTriggerFile)
  # significance cut
  Hgps = array(Htrigs[2])
  Hsig = array(Htrigs[4])
  Hfreq= array(Htrigs[3])
  survived_H_snr = []
  totalHNum = len(Hsig)
# vetoed trigger's SNR 
  for i in range(len(Hgps)):
    if not Hgps[i] in deadTime_segs: # i.e. if not vetoed
      survived_H_snr.append(Hsig[i])
 
 # print survived_H_snr
# vetoed triggers frequency
  survived_H_freq=[]
  for i in range(len(Hgps)):
    if not Hgps[i] in deadTime_segs: # i.e. if not vetoed
      survived_H_freq.append(Hfreq[i])
  #print survived_H_freq
# vetoed triggers time
  survived_H_peaktime=[]
  for i in range(len(Hgps)):
    if not Hgps[i] in deadTime_segs: # i.e. if not vetoed
      survived_H_peaktime.append(Hgps[i])
  
  survived_H_peaktime_hour = [(a-int(start_gps))/3600. for a in survived_H_peaktime]
  Hgps_hour = [(a-int(start_gps))/3600. for a in Hgps]
  hour_max_lim = max(Hgps_hour)
  #print survived_H_peaktime_hour
  #print Hgps_hour
 
# Plot SNR HIST 
  n, bins, patches = pylab.hist([math.log(t,10) for t in Hsig], bins = 100, bottom=0.001, facecolor='b',log=True)
  n2, bins2, patches2 = pylab.hist([math.log(t,10) for t in survived_H_snr], bins = bins, bottom=0.001, facecolor='r',log=True)
  pylab.xlabel('SNR')
  pylab.ylabel('Number of GW Triggers')
  pylab.title("Vetoed GW Triggers SNR Histogram")
  pylab.ylim(ymin=0.8)
  if len(patches)>0 and len(patches2)>0:
    pylab.legend((patches[0], patches2[0]), ("Before Veto","After Veto"),loc='upper right')
  plt.grid()
  # format x axis tick label
  hmin, hmax = pylab.gca().xaxis.get_view_interval()
  hmin = int(math.floor(hmin))
  if hmin == 0:
    hmin == 1
  hmax = int(math.ceil(hmax))
  tickLoc = []
  for b in range(hmin,hmax+1):
    tickLoc += [math.log(10**b * i,10) for i in range(1,10)]
  pylab.gca().xaxis.set_major_locator(MultipleLocator(1))
  pylab.gca().xaxis.set_major_formatter(FormatStrFormatter(r'$\mathdefault{10^{%d}}$'))
  pylab.gca().xaxis.set_minor_locator(FixedLocator(tickLoc))
  pylab.savefig("%s/Htriggers_hist.png"%baseDir,dpi=100)

# Plot Frequency Time SNR
  fig = plt.figure()
  ax = fig.add_subplot(1,1,1)
  ax.set_yscale('log')
  ax.grid(b=True, which='major', color='k', linestyle='-')
  ax.grid(b=True, which='minor', color='#ACACAA')
  ax.scatter(array(Hgps_hour)/24.0,Hsig,c='b',label='Before Veto')
  ax.scatter(array(survived_H_peaktime_hour)/24.0, survived_H_snr,edgecolors='none',c='r',label='After Veto')
  ax.set_xlim([0,hour_max_lim/24.0])
  ax.set_xlabel('Time in Days starting from %s'%start_utc)
  ax.set_ylabel('SNR')
  ax.set_title("Vetoed GW Triggers Time SNR Plot")
  pylab.legend(loc='upper right')
  pylab.savefig("%s/Htriggers_time_snr.png"%baseDir,dpi=100)

  fig = plt.figure()
  ax = fig.add_subplot(1,1,1) 
  ax.set_yscale('log')
  ax.grid(b=True, which='major', color='k', linestyle='-')
  ax.grid(b=True, which='minor', color='#ACACAA')
  ax.scatter(array(Hgps_hour)/24.0,Hfreq,c='b',label='Before Veto')
  ax.scatter(array(survived_H_peaktime_hour)/24.0, survived_H_freq,edgecolors='none',c='r',label='After Veto') 
  ax.set_xlim([0,hour_max_lim/24.0])
  ax.set_xlabel('Time in Days starting from %s'%start_utc)
  ax.set_ylabel('Central Frequency')
  ax.set_title("Vetoed GW Triggers Time Frequency Plot")
  pylab.legend(loc='upper right')
  pylab.savefig("%s/Htriggers_time_freq.png"%baseDir,dpi=100)

  fig = plt.figure()
  ax = fig.add_subplot(1,1,1)
  ax.set_xscale('log')
  ax.set_yscale('log')
  ax.grid(b=True, which='major', color='k', linestyle='-')
  ax.grid(b=True, which='minor', color='#ACACAA')
  ax.scatter(Hfreq,Hsig,c='b',label='Before Veto')
  ax.scatter(survived_H_freq,survived_H_snr,edgecolors='none',c='r',label='After Veto')
  ax.legend(loc='upper center')
  ax.set_ylabel('SNR')
  ax.set_xlabel('Central Frequency')
  ax.set_title("Vetoed GW Triggers Frequency SNR Plot")
  pylab.legend(loc='upper right')
  pylab.savefig("%s/Htriggers_freq_snr.png"%baseDir,dpi=100)
  
  #efficiencyList = array([float(channel_info[x]['vetoEfficiency'].split('%')[0]) for x in channel_info.keys()])
  #fig  = plt.figure()
  #ax = fig.add_subplot(1,1,1)
  #ax.hist(efficiencyList, 30)
  #ax.set_xlim([1, max(efficiencyList) + 2.0])
  #ax.set_ylim([0, len(efficiencyList)])
  #ax.grid(b=True, which='major', color='k', linestyle='-')
  #ax.grid(b=True, which='minor', color='#ACACAA')  
  #ax.set_xlabel('Efficiency')
  #ax.set_ylabel('Number of channels')
  #ax.set_title('Histogram plot of the veto efficiencies')
  #pylab.savefig('%s/Hist_efficiencies.png'%baseDir, dpi=100)  
  
  # Compuations done to get plot of cumulative efficiency v/s primary channel names
  primary_chan_names = []
  for channel in chan_name_list:
    tempName = channel.split('+')[0]
    primary_chan_names.append(tempName)
  primary_chan_names = unique(primary_chan_names)
  primary_chan_info = {}
  for iprim in primary_chan_names:
    primary_chan_info[iprim] = None
  
  for iprim in primary_chan_names:
    for chan in sorted(channel_info.keys()):
      #print 'chan: %s, prim_chan: %s'%(chan, iprim)
      if(chan.startswith(iprim) and channel_info[chan]["candidate"]=="True"):
	if(primary_chan_info[iprim]==None):
	  tempInfo = {}
	  tempInfo["vetoEfficiency"] = channel_info[chan]["vetoEfficiency"]
	  tempInfo["vetoSegs"] = veto_segs[chan]
	  primary_chan_info[iprim] = tempInfo
	else:
	  if(channel_info[chan]["vetoEfficiency"] > primary_chan_info[iprim]["vetoEfficiency"]):
	    primary_chan_info[iprim]["vetoEfficiency"] = channel_info[chan]["vetoEfficiency"]
          primary_chan_info[iprim]["vetoSegs"] |= veto_segs[chan]
  
  for iprim in primary_chan_names:
    if(primary_chan_info[iprim]==None):
      primary_chan_info.pop(iprim)
	    
  
  sorted_keys_by_efficiency = sorted(primary_chan_info, key=lambda x: float(primary_chan_info[x]['vetoEfficiency']), reverse=True)
  channel_number = arange(len(sorted_keys_by_efficiency))+1
  cumm_efficiency = zeros(len(sorted_keys_by_efficiency))
  cumDeadTime = primary_chan_info[sorted_keys_by_efficiency[0]]["vetoSegs"]
  vetoedHtrigs = []
  for j in range(totalHNum):
    if Hgps[j] in cumDeadTime:
	vetoedHtrigs.append(Hgps[j])
  cumm_efficiency[0] = float(len(vetoedHtrigs))/totalHNum
  del vetoedHtrigs
  i=1
  for iprim in sorted_keys_by_efficiency[1:]:
    cumDeadTime |= primary_chan_info[iprim]["vetoSegs"]
    vetoedHtrigs = []
    for j in range(totalHNum):
      if Hgps[j] in cumDeadTime:
	vetoedHtrigs.append(Hgps[j])
    eff = float(len(vetoedHtrigs))/totalHNum
    cumm_efficiency[i] = eff
    i+=1
    
  # Plot of Cumulative plot efficiencies v/s primary channel list
  fig = plt.figure(figsize=(8, 8))
  ax = fig.add_subplot(1, 1, 1)
  ax.plot(channel_number, cumm_efficiency*100)
  fig.subplots_adjust(bottom=0.5)
  plt.xticks(channel_number, sorted_keys_by_efficiency, rotation=90, size=6)
  ax.grid(b=True, which='major', color='k', linestyle='-')
  ax.grid(b=True, which='minor', color='#ACACAA')  
  ax.set_ylabel('Cumulative veto efficiencies of primary channels\nmaximised over secondary channels')
  ax.set_title("Plot of cumulative veto efficiencies over primary channels")
  pylab.savefig('%s/Cumulative_primary_efficiencies.png' %baseDir, dpi=100)
  
  
  # Compuations needed for getting cumulative veto efficiencies v/s secondary channels
  secondary_chan_names = []
  for channel in chan_name_list:
    tempName = channel.split('+')[1]
    secondary_chan_names.append(tempName)
  secondary_chan_names = unique(secondary_chan_names)
  secondary_chan_info = {}
  for isec in secondary_chan_names:
    secondary_chan_info[isec] = None
  
  for isec in secondary_chan_names:
    for chan in sorted(channel_info.keys()):
      #print 'chan: %s, sec_chan: %s'%(chan, isec)
      if(chan.endswith(isec) and channel_info[chan]["candidate"]=="True"):
	if(secondary_chan_info[isec]==None):
	  tempInfo = {}
	  tempInfo["vetoEfficiency"] = channel_info[chan]["vetoEfficiency"]
	  tempInfo["vetoSegs"] = veto_segs[chan]
	  secondary_chan_info[isec] = tempInfo
	else:
	  if(channel_info[chan]["vetoEfficiency"] > secondary_chan_info[isec]["vetoEfficiency"]):
	    secondary_chan_info[isec]["vetoEfficiency"] = channel_info[chan]["vetoEfficiency"]
          secondary_chan_info[isec]["vetoSegs"] |= veto_segs[chan]
  
  for isec in secondary_chan_names:
    if(secondary_chan_info[isec]==None):
      secondary_chan_info.pop(isec)
	    
  
  sorted_keys_by_efficiency = sorted(secondary_chan_info, key=lambda x: float(secondary_chan_info[x]['vetoEfficiency']), reverse=True)
  channel_number = arange(len(sorted_keys_by_efficiency))+1
  cumm_efficiency = zeros(len(sorted_keys_by_efficiency))
  cumDeadTime = secondary_chan_info[sorted_keys_by_efficiency[0]]["vetoSegs"]
  vetoedHtrigs = []
  for j in range(totalHNum):
    if Hgps[j] in cumDeadTime:
	vetoedHtrigs.append(Hgps[j])
  cumm_efficiency[0] = float(len(vetoedHtrigs))/totalHNum
  del vetoedHtrigs
  i=1
  for isec in sorted_keys_by_efficiency[1:]:
    cumDeadTime |= secondary_chan_info[isec]["vetoSegs"]
    vetoedHtrigs = []
    for j in range(totalHNum):
      if Hgps[j] in cumDeadTime:
	vetoedHtrigs.append(Hgps[j])
    eff = float(len(vetoedHtrigs))/totalHNum
    cumm_efficiency[i] = eff
    i+=1
    
  # Plot of Cumulative plot efficiencies v/s secondary channel list
  fig = plt.figure(figsize=(8, 8))
  ax = fig.add_subplot(1, 1, 1)
  ax.plot(channel_number, cumm_efficiency*100)
  #fig.subplots_adjust(bottom=0.5)
  #plt.xticks(channel_number, sorted_keys_by_efficiency, rotation=90, size=6)
  ax.grid(b=True, which='major', color='k', linestyle='-')
  ax.grid(b=True, which='minor', color='#ACACAA')  
  ax.set_ylabel('Cumulative veto efficiencies of secondary channels\nmaximised over primary channels')
  ax.set_title("Plot of cumulative veto efficiencies over secondary channels")
  pylab.savefig('%s/Cumulative_secondary_efficiencies.png' %baseDir, dpi=100)
  
  savetxt('%s/List_of_secondary_channels.txt'%(baseDir),array(channel_number, sorted_keys_by_efficiency).transpose() )
  
  
  
  pylab.close('all')
  print 'Finished plots'
  

    

  # add the plot to the page
  contents.append("<big><big><b>- Vetoed GW Triggers </b></big></big><br>")
  contents.append('<img id="H_hist" src="./Htriggers_hist.png" style="float: left; width: 50%;">')
  contents.append('<img id="H_time_snr" src="./Htriggers_time_snr.png" style="float: left; width: 50%;">')
  contents.append('<img id="H_time_freq" src="./Htriggers_time_freq.png" style="float: left; width: 50%;">')
  contents.append('<img id="H_freq_snr" src="./Htriggers_freq_snr.png" style="float: left; width: 50%;">')
  #contents.append('<img id="Hist_efficiencies" src="./Hist_efficiencies.png" style="float: left; width: 50%;">')
  contents.append('<img id="H_freq_snr" src="./Cumulative_primary_efficiencies.png" style="float: left; width: 50%;">')
  contents.append('<img id="Cumulative_efficiencies" src="./Cumulative_secondary_efficiencies.png" style="float: left; width: 50%;"><br>')

  ############################## Summary Info #################################

  # figure out the total dead time
  totalAnalysisTime = int(channel_info[chan_name]["analysisDuration"])
  deadTimePer = totalDeadTime * 1.0 / totalAnalysisTime * 100

  ## figure out the efficiency
  totalHNum = len(Hsig)
  vetoedHNum = totalHNum - len(survived_H_snr)
  combinedEff = vetoedHNum * 100.0 / (totalHNum or 1)
  
 
  
  

  # add summary
  contents.append("<big><big><b>- Summary</b></big></big><br><br>")
  contents.append("<b>Total Veto Efficiency: %.3f %% (%d / %d) </b><br>"%(combinedEff,vetoedHNum,totalHNum))
  contents.append("<b>Total Dead Time: %d s (%.2f %%)</b><br>"%(totalDeadTime,deadTimePer))  
  contents.append("<b>Required Accidental Veto Rate: %s Hz </b><br>"%(reqAccVetoRate))
  contents.append('<b><a href="List_of_secondary_channels.txt"> Secondary Channels in decreasing order of efficiency</a></b><br>')
  contents.append('<b><a href="vetoed_segment.txt">Total Vetoed Segments</a></b><br><br><br>')
 
  ############################# FOM Table ############################    
  ## make a table to the performance of each channel pair
 
  # get a unique fast/slow channels 
  fast_channels = set([])
  slow_channels = set([])
  linear = False
  for c in sorted(channel_info.keys()):
    pair = c.split("+")
    fast_channels.add(pair[0])
    if pair[1][3:] == "LINEAR":
      linear = pair[1]
    else:
      slow_channels.add(pair[1])

  # convert them to list so that we can alphabetize
  fast_channels = sorted(list(fast_channels))
  slow_channels = sorted(list(slow_channels))
  # if linear coupling is tested, make it the first raw
  if linear is not False:
    slow_channels = [linear] + slow_channels

  table3 = ["""
  <big><big><b>- Veto Efficiencies for Different Bilinear Combinations of Channels</b></big></big><br><br>
  The table below shows the veto efficiency for each bilinear combination of veto channels. Veto candidate channels are color-coded based on their efficiency.<br>
  <img src="fom_%s.png" ALT="spectrum"><br>
  <table border="1">
  <tbody>
  <tr>\n
  """%(color_scheme)]

  # every 15 column, put channel name for readability

  # first row - channel names
  table3.append("<th>Channel Name</th>")
  for i, c in enumerate(fast_channels):
    table3.append('<td>%s</td>'%(c))

  # content
  for sc in slow_channels:
    table3.append('<tr>')
    table3.append('<td>%s</td>'%(sc))
    for i, fc in enumerate(fast_channels):
      channel_name = "%s+%s"%(fc,sc)
      fom = float(channel_info[channel_name]["vetoEfficiency"])
      # normalize to 255 
      # FIXME: instead of nomalizing to 30%, weigh more on low percentage
      #        using something like log?
      eff_norm = 10 * eff_scale
      color_num = int((eff_norm - fom) * 255 / eff_norm)
      # change to html format
      rgb = color_map(color_num)[:3]
      color_hex = matplotlib.colors.rgb2hex(rgb)
      if channel_info[channel_name]["candidate"] == "False":
        color_hex = "white"
      table3.append('<td bgcolor="%s"><a href="channel_pages/%s_%s-report_page.html">%.2f%%</a></td>'%(color_hex,name_tag,channel_name,fom))
    table3.append("</tr>\n")

  table3.append("</tbody></table><br><br>")

  # add the table
  contents.append("".join(table3))

  ######################### candidate channel table ##########################
  
  ## make a summary
  sorted_keys_by_significance = sorted(channel_info, key=lambda x: float(channel_info[x]['vetoSignificance']), reverse=True)
  nVetoCandidates=0
  table = ["""
  <big><big><b>- Summary Table </b></big></big> <br><br> 
  This table summarizes the veto performance of each (pseudo) channel. <br>
  Channels that didn't pass the safety test are highlighted in red and veto candidate channels are highlighted in yellow.<br>
  Please click the channel name to see more detail information on each (pseudo) channel.<br>
  <br><br>
  <table border="1">
  <tbody>
  <tr>
  <th>(Pseudo) Channel</th>
  <th>Veto Efficiency (%)</th>
  <th>Dead Time (s)</th>
  <th>Efficiency / Dead Time</th>
  <th>Vetoed Injections </th>
  <th>Safety Probability</th>
  </tr>
  """]

  for chan in sorted_keys_by_significance:
    if channel_info[chan]["safety"] == "Unsafe":
      color = "red"
    elif channel_info[chan]["candidate"] == "True":
      color = "yellow"
    else:
      continue
    nVetoCandidates+=1
    table.append("""
            <tr bgcolor="%s">
            <td><a href="channel_pages/%s_%s-report_page.html">%s</a></td>
            <td>%s</td>
            <td>%s</td>
            <td>%s</td>
            <td>%s / %s</td>
            <td>%s (%s)</td>
            </tr>
            """%(color,name_tag,chan,chan,channel_info[chan]["vetoEfficiency"],channel_info[chan]["deadTime"],channel_info[chan]["efficiencyOverDeadtime"],channel_info[chan]["Nvetoed"],channel_info[chan]["totalInjectionNumber"],channel_info[chan]["safetyProbability"],channel_info[chan]["safety"]))

  table.append("</tbody></table><br><br>")
  table.append("Number of veto candidates:%d<br>"%(nVetoCandidates))

  contents.append("".join(table))


  ############################# Overlap Table ############################
    
  ## make an html page to show overlap
 
  overlap_page=["""
  <html>
  <head>
  <meta content="text/html; charset=ISO-8859-1"
  http-equiv="content-type">
  <title>Overlap Table</title>
  </head>
  <body>
  <big><big><big>Overlap Table</big></big></big><br>
  <br>
  <br>
  """]
 
  ## check overlap
  # 2D dict
  overlap = {}
  for c1 in sorted(veto_segs.keys()):
    overlap[c1]={}
    for c2 in sorted(veto_segs.keys()):
      overlap[c1][c2] = abs(veto_segs[c1] & veto_segs[c2])*1.0 / (abs(veto_segs[c2]) or 1) * 100


  table2 = ["""
    <h2>Overlap Between Vetoed Times </h2><br>
    The table below shows the overlaps between times vetoed by each pseudo channel.<br>
    The values in the table are:<br>
    (overlap time between two channels) / (total vetoed time by the channel on the column) * 100<br><br>
    <img src="overlap_%s.png" ALT="spectrum"><br>
    <table border="1">
    <tbody>
    <tr>\n
  """%color_scheme]

  # every 15 column, put channel name for readability

  # first row - channel names
  for i, c in enumerate(sorted(overlap)):
      if i % 15 == 0:
        table2.append("<th>Channel Name</th>")
      table2.append('<td><a href="channel_pages/%s_%s-report_page.html"><small>%s</small></a></td>'%(name_tag,c,c))
  table2.append("<th>Channel Name</th></tr>\n")

  # content
  for c1 in sorted(overlap):
      table2.append('<tr>')
      for i, c2 in enumerate(sorted(overlap[c1])):
        if i % 15 == 0:
          table2.append('<td><a href="channel_pages/%s_%s-report_page.html"><small>%s</small></a></td>'%(name_tag,c1,c1))
        # normalize to 255 
        color_num = int((100 - overlap[c1][c2]) * 255 / 100)
        # change to html format
        rgb = color_map(color_num)[:3]
        color = matplotlib.colors.rgb2hex(rgb)

        table2.append('<td bgcolor="%s">%.2f%%</td>'%(color,overlap[c1][c2]))
      table2.append('<td><a href="channel_pages/%s_%s-report_page.html"><small>%s</small></a></td>'%(name_tag,c1,c1))
      table2.append("</tr>\n")

  # last row - channel names
  for i, c in enumerate(sorted(overlap)):
      if i % 15 == 0:
        table2.append("<th>Channel Name</th>")
      table2.append('<td><a href="channel_pages/%s_%s-report_page.html"><small>%s</small></a></td>'%(name_tag,c,c))
  table2.append("<th>Channel Name</th></tr>")

  table2.append("</tbody></table><br><br>")

  # add the table
  overlap_page.append("".join(table2))

  # closing
  user=os.environ['USER']
  curTime=time.strftime('%m-%d-%Y %H:%M:%S',time.localtime())
  overlap_page.append("""
  <small>
  This page was created by user %s on %s
  </small>
  </body>
  </html>
  """%(user,curTime))
  
  ## save the page
  summary_page = open("%s/overlap.html"%(baseDir),"w")
  summary_page.write("".join(overlap_page))

  # add
  contents.append('<b><big><big>- <a href="./overlap.html">Overlap Table</a></big></big></b><br><br>')
  contents.append("This table shows how much veto segments are overlapping among the channels.<br><br><br>")

  ################################# closing ##################################
  user=os.environ['USER']
  curTime=time.strftime('%m-%d-%Y %H:%M:%S',time.localtime())
  git_info = git_version.verbose_msg.replace("<","(").replace(">",")").replace("\n","<br>")
  contents.append("""
  <small>
  This page was created by user %s on %s<br>
  %s
  </small>
  </body>
  </html>
  """%(user,curTime,git_info))

  ## save the page
  summary_page = open("%s/index.html"%(baseDir),"w")
  summary_page.write("".join(contents))
  

# =============================================================================
#
#                                  MAIN
# 
# =============================================================================

# parse commandline
opts = parse_commandline()

# access configuration file
cp = ConfigParser.ConfigParser()
cp.read(opts.ini_file)
name_tag = cp.get("general","tag")
reqAccVetoRate = cp.getfloat("data_conditioning","reqAccVetoRate")

# create output directory if not exist
baseDir = os.path.join(opts.out_dir,'%s_webpage'%name_tag)
if not os.path.exists(baseDir):
  if opts.verbose:
    print >> sys.stderr, "creating output directory %s..."%baseDir
  os.makedirs(baseDir)

# Figure out channels in the result dir and get info
# Make a list of the result files from veto_report
dir_list = os.listdir(opts.result_dir)

# color setting for tables
color_scheme = "jet"
color_map = pylab.get_cmap(color_scheme)

## get data for each channel
channel_info={}
veto_segs={}
chan_name_list = []
for chan_dir in dir_list:
	chan_dir = os.path.abspath(os.path.join(opts.result_dir,chan_dir))
	if opts.verbose:
	  	print >> sys.stderr, "gathering infomation from %s..."%(chan_dir)
  # Figure out channel name from directory name
  # Assumption is that tag doesn't contain "-" (checked in veto_setup)
  	chan_file = os.path.basename(chan_dir)
  	chan_name = chan_file.split("-",2)[-1]
  	chan_name_list.append(chan_name)

  	channel_info[chan_name] = bcvUtils.read_summary(os.path.join(chan_dir,"summary.txt"))
  	if channel_info[chan_name]["candidate"] == "True":
    		veto_segs[chan_name] = bcvUtils.read_segfile(os.path.join(chan_dir,"vetoSegments.txt"))

effs = [float(channel_info[c]["vetoEfficiency"]) for c in channel_info.keys()]
eff_scale = int(max(effs)) / 10 + 1

# overlap table color scaling
pylab.figure(figsize=(10,2))
fig = pylab.imshow(pylab.outer(pylab.ones(10),pylab.arange(1,0,-0.01)),cmap=pylab.get_cmap(color_scheme),origin="lower")
pylab.xlabel('Percentage (%)')
pylab.gca().set_yticks([])
pylab.savefig("%s/overlap_%s.png"%(baseDir,color_scheme),dpi=50)
pylab.close('all')

# fom table color scaling
pylab.figure(figsize=(10,2))
fig = pylab.imshow(pylab.outer(pylab.ones(eff_scale),pylab.arange(0.1*eff_scale,0,-0.01)),cmap=pylab.get_cmap(color_scheme),origin="lower")
pylab.xlabel('Percentage (%)')
pylab.gca().set_yticks([])
pylab.savefig("%s/fom_%s.png"%(baseDir,color_scheme),dpi=50)
pylab.close('all')


# do the work
summary_page(channel_info,veto_segs, chan_name_list)
if opts.verbose: print >> sys.stderr, "%s done!"%__prog__

