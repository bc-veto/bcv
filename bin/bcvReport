#!/home/detchar/opt/gwpysoft/bin/python
#
# Copyright (C) 2010  Tomoki Isogai
#
# This program is free software; you can redistribute it and/or modify it
# under the terms of the GNU General Public License as published by the
# Free Software Foundation; either version 3 of the License, or (at your
# option) any later version.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General
# Public License for more details.
#
# You should have received a copy of the GNU General Public License along
# with this program; if not, write to the Free Software Foundation, Inc.,
# 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.

"""
%prog --ini_file=File --result_dir=Directory --HTriggerFile=File --segment_file=File [options]

Tomoki Isogai (isogait@carleton.edu)
P. Ajith (ajith_p@ligo.caltech.edu)

This program does:
1) accumulate data from omegaveto, decide on threshold, and calculate FOMs
2) create plots
3) create webpages
"""

from __future__ import division

import sys
import  os
import time
import optparse
import ConfigParser
import re
import glob
from numpy import *

import math
import warnings
import matplotlib
matplotlib.use('Agg')
from pylab import *

try:
    import sqlite3
except ImportError:
    # pre 2.5.x
    from pysqlite2 import dbapi2 as sqlite3

from glue.segments import segment, segmentlist
from glue import segmentsUtils
sys.path.append("/home/sudarshan.ghonge/bcv_pipeline/bcv")
import git_version
import bcvUtils

__author__ = "Tomoki Isogai <isogait@carleton.edu>, P. Ajith <ajith_p@ligo.caltech.edu>"
__date__ = "1/5/2010"
__version__ = "1.0"
__prog__ = "veto_report"

def parse_commandline():
  """
  Parse the options given on the command-line.
  """

  parser = optparse.OptionParser(usage=__doc__,version=git_version.verbose_msg)

  parser.add_option("-i", "--ini_file", 
                    help="Path to the .ini file used. Required.")
  parser.add_option("-r", "--result_dir",
                    help="Directory with result files from omegaveto.m. Required.")
  parser.add_option("-c", "--couplingModel", default = "linear",
                    help="Coupling model. Either 'linear' or 'bilinear'. Required.")
  parser.add_option("-H", "--HTriggerFile", default=None,
                    help="KW trigger file for channel H")
  parser.add_option("-s", "--segment_file",
                    help="Segment file (created by veto_setup) used by the analysis.")
  parser.add_option("-A","--SNRcutoffH", type='float', default=0,
                    help="SNR cutoff for H triggers.")
  parser.add_option("-B","--SNRcutoffX", type='float', default=0,
                    help="SNR cutoff for X triggers.")
  parser.add_option("-a","--reqAccVetoRate", type='float', default="1.66e-06",
                    help="Required accidental veto rate. (Default: 1.66e-06)")
  parser.add_option("-S","--vetoSignThresh",type='float',default="10",
                    help="Veto significance threshold. (Default: 10)")
  parser.add_option("-p","--positive_window",type="float", default = 1,
                    help="Positive veto-window size in second.")
  parser.add_option("-n","--negative_window",type="float", default = 1,
                    help="Negative veto-window size in second.")
  parser.add_option("-I", "--injection_file", default=None,
                    help="File that contains HW injection times. If given, code will check safety against those HW injections.")
  parser.add_option("-x", "--safety_thresh",type="int",default=-5,
                      help="Threshold 10**x will be applied for safety check if given. (Default: -5)")
  parser.add_option("-l","--scratch_dir",default=".",
                    help="Scratch directory to be used for database engine. Specify local scratch directory for better performance and less fileserver load. (Default: current directory)")
  parser.add_option("-o","--out_dir", default=".",
                    help="Output directory. (Default: current directory)")
  parser.add_option("-b","--base_dir", default=".",
                    help="Base directory containing the analysis results (Default: current directory)")
  parser.add_option("--use_rMax", action="store_true", default = False,
                    help="use rMax instead of r")
  parser.add_option("-v", "--verbose", action="store_true",
                    default=False, help="Run verbosely. (Default: None)")
  parser.add_option("-L", "--standalone", action="store_true", default=False, help="Run standalone (redirects many file writes to scratch_dir). (Default: FALSE)")
  parser.add_option("-T", "--performance_test", action="store_true", default=False, help="Output performance data. (Default: FALSE)")
  parser.add_option("-m", "--memdatabase", action="store_true", default=False, help="Use :memory: instead of a db file WARNING EXPERIMENTAL - MIGHT BREAK CLUSTER (Default: FALSE)")


  opts, args = parser.parse_args()
  
  ########################## sanity check ####################################
  
  # check if necessary input exists
  for o in ("ini_file","segment_file","result_dir","HTriggerFile"):
    if getattr(opts,o) is None:
      parser.error("Error: --%s is a required parameter"%o)
    if not os.path.exists(getattr(opts,o)):
      parser.error("Error: --%s not found."%o)
  if opts.couplingModel not in ("linear", "bilinear"):
    parser.error("Error: --couplingModel has to be specified and one of 'linear' or 'bilinear'.")
  
      
  ######################### show parameters ##################################
  if opts.verbose:
      print >> sys.stderr, ""
      print >> sys.stderr, "running %s..."%__prog__
      print >> sys.stderr, git_version.verbose_msg
      print >> sys.stderr, ""
      print >> sys.stderr, "*************** PARAMETERS **********************"
      for o in opts.__dict__.items():
        print >> sys.stderr, o[0]+":"
        print >> sys.stderr, o[1]
      print >> sys.stderr, ""
  
  return opts


# =============================================================================
#
#                              Calculation Functions
#
# =============================================================================


def calcProbDensity(r,rVec):
  """
  CALCPROBDENSITY - Calculate the probability density and cumulative
  distribution function of a sample of random variables.

  Usage: [probDens] = calcprobdensity(x)

  r        : Sample
  probDens : Probability denstity

  Modified from calcprobdensity.m by P. Ajith
  """
  probDens = []
  dx = rVec[1] - rVec[0]
  i = 0
  counter = 0
  cur_r = r.fetchone()
  for x in rVec:
    while cur_r is not None and cur_r[0] < x + dx:
      cur_r = r.fetchone()
      i += 1
      counter += 1
    # replace 0 with small number?
    # probDens.append(i is not 0 and i or 0.000001)
    probDens.append(i)
    i = 0

  return [array(probDens) / counter / dx, counter]
  #return array(probDens)

def findVetoThreshold(cursor, reqAccVetoRate, effNumSecs):
  """
  Modified from findVetoThreshold() by T. Isogai

  Returns a threshold on abs(r) that respects requested accidental veto rate
  and a list of (threhsold, accidental veto rate).
  
  """
  
  reqN = reqAccVetoRate * effNumSecs

  # requested accidental veto rate is too tight
  if reqN < 1:
    return 1.0, [(1.0, 0.0)]
 
  st = time.time()
  query = cursor.execute("select count(*) from data where tau != 0")
  el = time.time() - st
  #print >> sys.stderr, "select count(*) took", el, "secs"
  count = query.fetchone()[0]
  st = time.time()
  query = cursor.execute("select abs(%s) from data where tau != 0 order by abs(%s) desc"%(statistics,statistics))
  el = time.time() - st
  #print >> sys.stderr, "select abs(%s) order by abs(%s) desc took", el, "secs"

  #print >> sys.stderr, "Processing", count, "items"
  rst = 1  #  set this to 1 to reset accidental veto rate; otherwise use 0
  thresh_array = empty((count,2))
  i = 0
  for n in query:
    thresh_array[i][0] = n[0]
    thresh_array[i][1] = (i+1.0)/effNumSecs
    i += 1
  
  i_array = arange(len(thresh_array))+1
  
  if reqN > len(thresh_array):
    print >> sys.stderr, "Requested accidental veto rate is too loose..."
    if rst:
    # requested accidental veto rate is too loose

    # Added, 6-14-15
    # reset required accidental veto rate to obtain nonzero r_thresh value
	reqAccVetoRateOrig = reqAccVetoRate
    	reqAccVetoRate = len(thresh_array)/effNumSecs
    	print >> sys.stderr, "Using required accidental veto rate of ",reqAccVetoRate
	if reqAccVetoRate > reqAccVetoRateOrig: # values smaller than req. veto rate are okay, but will not use larger values
		print >> sys.stderr, "WARNING: New accidental veto rate of ",reqAccVetoRate, " exceeds original rate of ",reqAccVetoRateOrig
		print >> sys.stderr, "rThresh will be set to 0."
		rThresh = 0.0 # original
	else:
    		reqN = reqAccVetoRate * effNumSecs
    		rThresh = thresh_array[int(reqN-1)][0]
    else:
	rThresh = 0.0 # original
  else:  
    rThresh = thresh_array[int(reqN-1)][0]
  rThreshList = thresh_array

  return rThresh, rThreshList

def applyVetoThreshold(channel, resultsDir, reqAccVetoRate, gpsTriggerHList, numXTrigs,scratch_dir,verbose,outDir=None,perftest=True,memdb=False,standalone=False):
  """
  Modified from applyvetothreshold.m by P. Ajith
  """
  # Determine where things like db files and summaries should be saved.
  # These go into resultsDir as part of the pipeline, scratch_dir standalone.
  storage_dir = {True: scratch_dir, False: resultsDir}[standalone]

  # sanity check
  if outDir == None:
    outDir = resultsDir

  rVec = linspace(0,1,50)

  dbFile = os.path.join(storage_dir,"%s-data.db"%channel)
  # if the file already exists, rename the old one
  bcvUtils.rename(dbFile)

  try:
    global working_filename # so that it can be erased when error occurs
    working_filename = bcvUtils.get_connection_filename(\
                       dbFile, tmp_path=scratch_dir)

    if memdb:
        connection = sqlite3.connect(":memory:")
    else:
        connection = sqlite3.connect(working_filename)
    cursor = connection.cursor()
    if verbose:
      print >> sys.stderr, "setting the temp_store_directory to %s" %scratch_dir
    connection.cursor().execute('PRAGMA temp_store_directory = "%s"'%scratch_dir)


    cursor.execute("create table data (tau double, r double, rMax double, trigHCentTime double, trigXCentTime double, trigHCentFreq int, trigXCentFreq int, trigHTrgSignf double, trigXTrgSignf double, trigHDuration double, trigXDuration double)")

    # indexes against common stuff - experimental
    cursor.execute("create index tau_idx on data(tau)")
    cursor.execute("create index r_idx on data(%s)"%statistics)

    logFiles = []

    timeDirs = [d for d in os.listdir(resultsDir) if os.path.isdir(os.path.join(resultsDir,d)) and re.match("\d{9,10}_\d{9,10}",d)]
    
    if perftest:
        start = time.time()
        if verbose: print >> sys.stderr, "Processing time files..."
    i = 0
    for timeDir in timeDirs:
      tableName = "segment_"+os.path.splitext(timeDir)[0]
      timeDir = os.path.join(resultsDir,timeDir)
      timeFiles = [os.path.join(timeDir,f) for f in os.listdir(timeDir) if f.startswith("corrstat_timeshift") and f.endswith(".dat") and len(f) > 12]

      # add each summary file to db
      summaryFile = os.path.join(timeDir,"summary.txt")
      if not os.path.isfile(summaryFile):
          print "Summary file %s does not exist"%(summaryFile)
          continue
      summaryData = bcvUtils.read_summary(summaryFile)

      if "SNRcutoffH" in summaryData.keys():
        if float(summaryData["SNRcutoffH"]) >= opts.SNRcutoffH or float(summaryData["SNRcutoffX"]) >= opts.SNRcutoffX:
          print >> sys.stderr, "Error: The original SNR cutoff is higher than the new cutoff. You need to rerun the whole process again."
          sys.exit(1)

        print "working!!"
        sys.exit(1)
        

      cursor.execute("create table %s (varName txt, value)"%(tableName))
      cursor.executemany("insert into %s values (?,?)"%(tableName), summaryData.items())

      logFiles.append(summaryData["logFile"])

      for timeFile in timeFiles:
        if verbose: print >> sys.stderr, "processing %s..."%timeFile
        for line in open(timeFile):
          # read in the data
          data = line.split()
          cursor.execute("insert into data (tau, r, rMax, trigHCentTime, trigXCentTime, trigHCentFreq, trigXCentFreq, trigHTrgSignf, trigXTrgSignf, trigHDuration,trigXDuration) values (?,?,?,?,?,?,?,?,?,?,?)",(data[0],data[1],data[2],data[3],data[4],data[5],data[6],data[7],data[8],data[9],data[10]))
        i = i + 1
    if i==0:
        print "No data to analyze"
        return None

    if perftest:
        elapsed = time.time() - start
        if verbose: print >> sys.stderr, "#### Processed %d time files in %f seconds ####"%(i,elapsed)
        data_length = int(cursor.execute("select count(*) from data").fetchone()[0])
        if verbose: print >> sys.stderr, "Table `data` contains %d rows"%data_length

        start = time.time()
        if verbose: print >> sys.stderr, "Calculating probability densities..."

    probDensTS, countTS = calcProbDensity(cursor.execute("select abs(%s) from data where tau != 0 order by abs(%s)"%(statistics,statistics)),rVec)

    probDensZL, countZL = calcProbDensity(cursor.execute("select abs(%s) from data where tau == 0 order by abs(%s)"%(statistics,statistics)),rVec)

    if perftest:
        elapsed = time.time() - start
        if verbose: print >> sys.stderr, "#### Calculated in %f seconds ####"%elapsed

    numTimeShifts = int(cursor.execute("select count(distinct tau) from data").fetchone()[0]) - 1

    analysisStartTime = analyzed_segs[0][0]
    analysisEndTime = analyzed_segs[-1][-1]
    analysisDuration = abs(analyzed_segs)

    effNumSecs = analysisDuration*numTimeShifts

    # compute the veto threshold corresponding to the given acc. veto. RATE 
    if perftest:
        start = time.time()
    rThresh, rThreshList = findVetoThreshold(cursor, reqAccVetoRate, effNumSecs)
    if perftest:
        elapsed = time.time() - start
        if verbose:
            print >> sys.stderr, "found veto threshold", rThresh, "in", elapsed, "sec"
            
            
        start = time.time()
        if verbose: print >> sys.stderr, "Building fom curve..."

    # build a trigXCentTimeData
    query = cursor.execute("select trigXCentTime, %s, tau from data"%(statistics))
    trigXCentTimeData = {}
    for txct, r, tau in query:
      if tau not in trigXCentTimeData:
        trigXCentTimeData[tau] = {}
      if r not in trigXCentTimeData[tau]:
        trigXCentTimeData[tau][r] = []
      trigXCentTimeData[tau][r].append(txct)

    fom_curve = []
    numHTrigs = len(gpsTriggerHList['centralTime'])    
    rlist = linspace(0,1,1000)
    imax = len(rlist)
    i = 0
    for _r in rlist:
      r = (0,0)
      for z in rThreshList:
        if z[0] <= _r:
          r = z
          break
      if r[0] == 0: continue
      
      #try:
      if trigXCentTimeData:
      	v_segs = _get_veto_segs(cursor,r[0],analyzed_segs,False,trigXCentTimeData)
      #if v_segs:
      	v_N = len([t for t in gpsTriggerHList['centralTime'] if t in v_segs])
      else: # presumably, if this fails, v_segs is empty
      	v_N = 0
      v_Eff = 100 * v_N / (numHTrigs or 1)
      fom_curve.append((r[0],r[1],v_Eff))
      if verbose and (i % min(int(i/25+1),24) == 0): print >> sys.stderr, i, "/", imax
      i += 1

    if perftest:
        elapsed = time.time() - start
        if verbose: print >> sys.stderr, "#### Calculated in %f seconds ####"%elapsed
    
    # compute the veto threshold corresponding to the given acc. veto. PROBABILITY 

    # get veto segments
    veto_segments = _get_veto_segs(cursor,rThresh,analyzed_segs)
    # save in db
    #try:
    if veto_segments:
    	bcvUtils.write_segs_db(cursor,veto_segments,"vetoSegments")
    # save in txt file
    	vetoSegFile = os.path.join(storage_dir,"vetoSegments.txt")
    	segmentsUtils.tosegwizard(open(vetoSegFile,'w'),veto_segments)
    else:
        print >> sys.stderr, "No veto segments..."
	veto_segments  = []
        vetoSegFile = os.path.join(storage_dir,"vetoSegments.txt")
        segmentsUtils.tosegwizard(open(vetoSegFile,'w'),veto_segments)
        
    N = int(cursor.execute("select count(%s) from data where tau != 0 and abs(%s) >= ?"%(statistics,statistics),(rThresh,)).fetchone()[0])
    accVetoRate = N / (effNumSecs or 1)

    if opts.injection_file is not None:
      cursor, Nvetoed, Nexp, probability, safety, totalInjNum = injection_check(cursor, opts.injection_file, veto_segments, analyzed_segs, opts.safety_thresh)
    else:
      Nvetoed = "n/a"
      Nexp = "n/a"
      probability = "n/a"
      safety = "n/a"
      totalInjNum = "n/a"

    # compute the veto efficiency, use percentage, accidental veto prob.
    # and veto significance
    numHTrigs = len(gpsTriggerHList['centralTime'])
    if veto_segments:
    	vetoedTrigs = len([t for t in gpsTriggerHList['centralTime'] if t in veto_segments])
        vetoedNum = int(cursor.execute("select count(%s) from data where tau == 0 and abs(%s) >= ?"%(statistics,statistics),(rThresh,)).fetchone()[0])
    else:
	vetoedNum = 0
        vetoedTrigs = 0
    vetoEff = 100 * vetoedTrigs / (numHTrigs or 1)
    accNum = int(cursor.execute("select count(%s) from data where tau != 0 and abs(%s) >= ?"%(statistics,statistics),(rThresh,)).fetchone()[0])
    accVetoProb = accNum / (numHTrigs * numTimeShifts or 1)
    if veto_segments:
    	deadTime = abs(veto_segments)
    else:
	deadTime = 0
    deadTimePer = 100 * deadTime / (analysisDuration or 1)
    vetoEff_deadTime = vetoEff / (deadTimePer or 1)

    ZLNum = int(cursor.execute("select count(%s) from data where tau == 0"%statistics).fetchone()[0])
    vetoEffCoinc = vetoedNum / (ZLNum or 1)

    veto_segments_TS_list = get_veto_segs(cursor,rThresh,analyzed_segs,timeShift=True)

    #print >> sys.stderr, "Time shift veto_segments_TS_list: ",veto_segments_TS_list # 6-15-2015
    #print >> sys.stderr, "gpsTriggerHList['centralTime']: ",gpsTriggerHList['centralTime'] # 6-15-2015

    #vetoEffCoincTS = []
    vetoedNumTS=accNum
    TSNum= int(cursor.execute("select count(%s) from data where tau != 0"%(statistics)).fetchone()[0])
   # for veto_segments_TS in veto_segments_TS_list:
   #   vetoedNumTS += len([t for t in gpsTriggerHList['centralTime'] if t in veto_segments_TS[1]])
   #   if verbose: #print veto_segments_TS[0]
   #		print >> sys.stderr, "veto_segments_TS[0]: ",veto_segments_TS[0] # 6-15-2015
   #		print >> sys.stderr, "veto_segments_TS[1]: ",veto_segments_TS[1] # 6-15-2015
   #		#print >> sys.stderr, "veto_segments_TS[1]: ",veto_segments_TS[1].split() # 6-15-2015
   #		print >> sys.stderr, "vetoedNumTS: ",vetoedNumTS # 6-15-2015
   #   TSNum_qstring = "select count(%s) from data where tau == %s"%(statistics,veto_segments_TS[0],)
   #   print >> sys.stderr, "TSNum_qstring : %s"%TSNum_qstring
   #   TSNum += int(cursor.execute(TSNum_qstring).fetchone()[0]) or 0

#      TSNum = int(cursor.execute("select count(%s) from data where tau == ?"%statistics,(veto_segments_TS[0],)).fetchone()[0])
      #vetoEffCoincTS.append(vetoedNumTS / (TSNum or 1))
    
    #print >> sys.stderr, "vetoEffCoincTS: %s"%vetoEffCoincTS  # 6-15-2015
    vetoEffCoincTS = vetoedNumTS/(TSNum or 1)

    if ((vetoEffCoincTS!=0) and (vetoEffCoinc != 0)): # added/changed 2-1-2016
	vetoSignificance = vetoEffCoinc / vetoEffCoincTS
    else:
	vetoSignificance = vetoEffCoinc
	 
    #vetoSignificance = vetoEffCoinc / (mean(array(vetoEffCoincTS)) or 1)
    candidate = vetoSignificance > opts.vetoSignThresh
    if verbose: 
	print >> sys.stderr, "vetoSignificance: %s"%vetoSignificance
	print >> sys.stderr, "vetoSignificance Threshold input: %s"%(opts.vetoSignThresh)

    logFile = os.path.join(storage_dir,"log.txt")
    os.system("echo '# Accumulated Log File' > %s"%logFile)
    for log in sorted(logFiles):
      os.system("echo %s >> %s"%(log,logFile))
      os.system("cat %s >> %s"%(log,logFile))

    textSummary = os.path.join(storage_dir,"summary.txt")

    results = {"rThresh":rThresh,
               "vetoEfficiency":vetoEff,
               "accidentalVetoProb":accVetoProb,
               "accidentalVetoRate":accVetoRate,
               "reqAccVetoRate":reqAccVetoRate,
               "vetoEfficiencyCoincTrigs":vetoEffCoinc,
               "vetoSignificance":vetoSignificance,
               "candidate":str(candidate),
               "numTrigsH":numHTrigs,
               "SNRcutoffH":opts.SNRcutoffH,
               "numTrigsX":numXTrigs,
               "SNRcutoffX":opts.SNRcutoffX,
               "deadTime":deadTime,
               "analysisStartTime":analysisStartTime,
               "analysisEndTime":analysisEndTime,
               "analysisDuration":analysisDuration,
               "deadTimePercentage":deadTimePer,
               "efficiencyOverDeadtime":vetoEff_deadTime,
               "Nvetoed":Nvetoed,
               "Nexp":Nexp,
               "totalInjectionNumber":totalInjNum,
               "safetyProbability":probability,
               "safety":safety,
               "configurationFile":summaryData["configurationFile"],
               "couplingModel":summaryData["couplingModel"],
               "highPassCutoff":summaryData["highPassCutoff"],
               "vetoSegmentFile":vetoSegFile, #fix this: need to handle when empty
               "outDir":resultsDir,
               "logFile":logFile,
               "txtSummary":textSummary,
               "dbSummary":dbFile}

    if verbose:
      for k in results:
        print >> sys.stderr, "%s: %s"%(k,results[k])

    cursor.execute("create table results (varName txt, value)")
    cursor.executemany("insert into results values (?,?)", results.items())
    connection.commit()

    bcvUtils.save_db(cursor, 'ALL', dbFile, working_filename)

    # write text summary
    contents=[]
    contents.append("rThresh: %.3f"%rThresh)
    contents.append("vetoEfficiency: %.3f"%vetoEff)
    contents.append("accidentalVetoProb: %.2e"%accVetoProb)
    contents.append("accidentalVetoRate: %.2e"%accVetoRate)
    contents.append("reqAccVetoRate: %.2e"%reqAccVetoRate)
    contents.append("vetoEfficiencyCoincTrigs: %.3f"%vetoEffCoinc)
    contents.append("vetoSignificance: %.3f"%vetoSignificance)
    contents.append("candidate: %s"%candidate)
    contents.append("numTrigsH: %d"%numHTrigs)
    contents.append("SNRcutoffH: %d"%opts.SNRcutoffH)
    contents.append("numTrigsX: %d"%numXTrigs)
    contents.append("SNRcutoffX: %d"%opts.SNRcutoffX)
    contents.append("deadTime: %d"%deadTime)
    contents.append("analysisDuration: %d"%analysisDuration)
    contents.append("analysisStartTime: %d"%analysisStartTime)
    contents.append("analysisEndTime: %d"%analysisEndTime)
    contents.append("deadTimePercentage: %.4f"%deadTimePer)
    contents.append("efficiencyOverDeadtime: %.2f"%vetoEff_deadTime)
    #contents.append("Nvetoed: %d"%int(Nvetoed))
    contents.append("Nvetoed: %s"%Nvetoed)
    contents.append("Nexp: %s"%Nexp)
    contents.append("totalInjectionNumber: %s"%totalInjNum)
    contents.append("safetyProbability: %s"%probability)
    contents.append("safety: %s"%safety)
    contents.append("configurationFile: %s"%summaryData["configurationFile"])
    contents.append("couplingModel: %s"%summaryData["couplingModel"])
    contents.append("highPassCutoff: %s"%summaryData["highPassCutoff"])
    contents.append("vetoSegmentFile: %s"%vetoSegFile)
    contents.append("outDir: %s"%resultsDir)
    contents.append("logFile: %s"%logFile)
    contents.append("txtSummary: %s"%textSummary)
    contents.append("dbSummary: %s"%dbFile)

    open(textSummary,'w').write("\n".join(contents))

    # =========================================================================
    #
    #                                   Plot
    #
    # =========================================================================
  
    if verbose:
      print >> sys.stderr, "creating plots..."
  
    plotDir = os.path.join(baseDir,"plots") # presumably we want to access this data later
    if not os.path.isdir(plotDir):
      os.makedirs(plotDir)
    prefix = os.path.join(plotDir,channel)
  
    matplotlib.rcParams.update({
        "font.size": 8.0,
        "axes.titlesize": 18.0,
        "axes.labelsize": 18.0,
        "xtick.labelsize": 13.0,
        "ytick.labelsize": 13.0,
        "legend.fontsize": 15.0})
  
    # time shift vs cross correlation
    tau_rTS = zip(*cursor.execute("select tau, abs(%s) from data where tau != 0"%statistics).fetchall())
    if len(tau_rTS) > 0:
      plot(tau_rTS[0], tau_rTS[1], 'b.', label = "Time-shift")
    del tau_rTS
    tau_rZL = zip(*cursor.execute("select tau, abs(%s) from data where tau == 0"%statistics).fetchall())
    if len(tau_rZL) > 0:
      plot(tau_rZL[0], tau_rZL[1], 'rx', label = "Zero-lag")
    del tau_rZL
    # FIXME: if we vary time shift interval, this should not be hard-coded.
    xlim([timeShiftMin,timeShiftMax])
    xlabel("Time-shift between X and H [sec]")
    ylabel("Abs. value of cross correlation (|r|)")
    title("Time-shift plot of the correlation")
    legend(loc='upper right')
    grid()
    bcvUtils.rename("%s_TimeShiftPlot.png"%prefix)
    savefig("%s_TimeShiftPlot.png"%prefix)
    bcvUtils.rename("%s_TimeShiftPlot.thumb.png"%prefix)
    savefig("%s_TimeShiftPlot.thumb.png"%prefix,dpi=40)
    close('all')
  
    # time vs SNR
    semilogy((gpsTriggerHList["centralTime"]-analysisStartTime)/3600, gpsTriggerHList["triggerSignificance"], 'c.', markersize=10, label = "All trigs.");
    time_sig = zip(*cursor.execute("select trigHCentTime, trigHTrgSignf from data where tau == 0 and abs(%s) >= ?"%statistics,(rThresh,)).fetchall()) 
    if len(time_sig) > 0:
      trigHCentTime, trigHTrgSignf = time_sig
      del time_sig
      plot((array(trigHCentTime,) - analysisStartTime) / 3600, trigHTrgSignf, 'k.', label = "Vetoed trigs.")
      del trigHCentTime
    utcTime = os.popen('tconvert %d'%analysisStartTime).readline()
    xlabel("Hours starting from %s"%utcTime)
    ylabel("Trigger SNR")
    legend(loc='upper right')
    grid()
    title("Trigger SNR Vs Central time")
    bcvUtils.rename("%s_TimeSignificPlot.png"%prefix)
    savefig("%s_TimeSignificPlot.png"%prefix)
    bcvUtils.rename("%s_TimeSignificPlot.thumb.png"%prefix)
    savefig("%s_TimeSignificPlot.thumb.png"%prefix,dpi=40)
    close('all')
  
    # time vs frequency
    semilogy((gpsTriggerHList["centralTime"]-analysisStartTime)/3600, gpsTriggerHList["centralFrequency"], 'c.',markersize=10, label = "All trigs.")
    time_freq = zip(*cursor.execute("select trigHCentTime, trigHCentFreq from data where tau == 0 and abs(%s) >= ?"%statistics,(rThresh,)).fetchall()) 
    if len(time_freq) > 0:
      trigHCentTime, trigHCentFreq = time_freq
      del time_freq
      plot((array(trigHCentTime) - analysisStartTime) / 3600, trigHCentFreq, 'k.', label = "Vetoed trigs.")
      del trigHCentTime
    legend(loc='upper right')
    grid()
    xlabel("Hours starting from %s"%utcTime)
    ylabel("Central Frequency")
    title("Central frequency Vs Central time")
    bcvUtils.rename("%s_TimeCentFreqPlot.png"%prefix)
    savefig("%s_TimeCentFreqPlot.png"%prefix)
    bcvUtils.rename("%s_TimeCentFreqPlot.thumb.png"%prefix)
    savefig("%s_TimeCentFreqPlot.thumb.png"%prefix,dpi=40)
    close('all')
  
    # frequency vs SNR
    plot(gpsTriggerHList["centralFrequency"], gpsTriggerHList["triggerSignificance"], 'r.',markersize=12, label = "All trigs.")
    if locals().has_key("trigHCentFreq"):
      plot(trigHCentFreq, trigHTrgSignf, 'k.', label = "Vetoed trigs.")
      del trigHCentFreq, trigHTrgSignf
    ax = gca()
    #ax.set_xscale('log')
    ax.set_yscale('log')
    ax.set_xlim(1000, 4000)
    ax.set_ylim(5, 100)
    legend(loc='upper left')
    #grid()
    xlabel("Central Frequency")
    ylabel("Trigger SNR")
    title("Trigger SNR Vs Central frequency")
    bcvUtils.rename("%s_CentFreqSignificPlot.png"%prefix)
    savefig("%s_CentFreqSignificPlot.png"%prefix)
    bcvUtils.rename("%s_CentFreqSignificPlot.thumb.png"%prefix)
    savefig("%s_CentFreqSignificPlot.thumb.png"%prefix,dpi=40)
    close('all')
  
    # cross correlation histogram
    if max(probDensTS) > 0:
      semilogy(rVec, probDensTS,'b',label="TS. N-trigs=%d. V-trigs= %d"%(TSNum, vetoedNumTS),drawstyle="steps")
    if max(probDensZL) > 0:
      semilogy(rVec, probDensZL,'r',label="ZL. Ntrigs=%d. V-trigs= %d"%(ZLNum, vetoedNum),drawstyle="steps")
    axvline(x=rThresh,ymin=0.001,ymax=10,color='k',ls="--")
    legend(loc='upper right')
    grid()
    xlabel("Abs. value of cross correlation (|r|)")
    ylabel("Prob. Density")
    legend()
    title("Correlation Histograms")
    bcvUtils.rename("%s_CrossCorrHist.png"%prefix)
    savefig("%s_CrossCorrHist.png"%prefix)
    bcvUtils.rename("%s_CrossCorrHist.thumb.png"%prefix)
    savefig("%s_CrossCorrHist.thumb.png"%prefix,dpi=40)
    close('all')

    # accidental veto rate vs efficiency
    if len(fom_curve) > 0:
      threshes, accRates, effs = zip(*fom_curve)
      if accRates[0] != 0.0:
        semilogx(accRates,effs,'b',linewidth=2)
        # find out |r| thresh for one per day, one per week acc. veto rate
        week_r = None
        day_r = None
        for i in range(len(threshes)):
          # one per week
          if week_r is None and accRates[i] < 1.0/604800:
            week_r = (threshes[i],accRates[i],effs[i])
          # one per day
          if day_r is None and accRates[i] < 1.0/86400:
            day_r = (threshes[i],accRates[i],effs[i])
        if week_r is not None:
          semilogx([week_r[1]],[week_r[2]],'go',markersize=10,
                   label="Acc. Veto Rate: 1/week\n|r| Threshold: %.3f"%week_r[0])
        if day_r is not None:
          semilogx([day_r[1]],[day_r[2]],'r*',markersize=14,
                   label="Acc. Veto Rate: 1/day\n|r| Threshold: %.3f"%day_r[0])
      grid()
      xlabel("Accidental veto rate [Hz]")
      ylabel("Veto efficiency [%]")
      legend(loc="upper left")
      title("Efficiency Vs Acc. veto Rate for diff. thresholds")
      bcvUtils.rename("%s_ROC.png"%prefix)
      savefig("%s_ROC.png"%prefix)
      bcvUtils.rename("%s_ROC.thumb.png"%prefix)
      savefig("%s_ROC.thumb.png"%prefix,dpi=40)
      close('all')

  finally:
    # clean up all the tmp databases
    for db in ("working_filename",):
      if globals().has_key(db):
        db = globals()[db]
        if verbose:
          print >> sys.stderr, "removing temporary workspace '%s'..."%db
        os.remove(db)

  return results

def get_veto_segs(cursor,veto_thresh,analyzed_segs,timeShift=False):
  """
  Create a veto segment list with a given KW significance threshold.
  Take an intersection with analyzed segments so that all the veto segments
  stays in analyzed segs.
  """
  if timeShift:
    taus = unique(map(int,linspace(timeShiftMin,timeShiftMax,numTimeShifts)))
    taus = [t for t in taus if t != 0]
    #taus = analyzed_segs.keys()
    veto_seg_list = []
    for tau in taus:
      if tau and statistics and veto_thresh:
	print >> sys.stderr, "tau: %s"%tau
	print >> sys.stderr, "statistics: %s"%statistics
	print >> sys.stderr, "veto_thresh: %s"%veto_thresh
	q_string = "select trigXCentTime from data where tau == %d and abs(%s) >= %f"%(tau,statistics,veto_thresh)
	print >> sys.stderr, q_string
      	#veto_times = cursor.execute("select trigXCentTime from data where tau == ? and abs(%s) >= ?"%(statistics),(tau,veto_thresh))
	veto_times = cursor.execute(q_string)
      	veto_segs = segmentlist([bcvUtils.get_segment(t[0], opts.positive_window, opts.negative_window) for t in veto_times])
	print >> sys.stderr, "Time shift veto_segs: ",veto_segs # 6-15-2015
        veto_seg_list.append((tau,veto_segs.coalesce() & analyzed_segs))
        print >> sys.stderr, "veto_seg_list append successful..."
      else:
	#veto_segs = [0,0,0,0,0]
      	#veto_seg_list.append((tau,veto_segs & analyzed_segs))
        print >> sys.stderr, "Nothing appended to veto_seg_list..."
    #print >> sys.stderr, "Time shift veto_seg_list: ",veto_seg_list # 6-15-2015 
    return veto_seg_list
  else:
    q_stringZ = "select trigXCentTime from data where tau == 0 and abs(%s) >= %f"%(statistics,veto_thresh)
    veto_times = cursor.execute(q_stringZ)
    #veto_times = cursor.execute("select trigXCentTime from data where tau == 0 and abs(%s) >= ?"%(statistics),(veto_thresh,))
    veto_segs = segmentlist([bcvUtils.get_segment(t[0], opts.positive_window, opts.negative_window) for t in veto_times])
    return veto_segs.coalesce() & analyzed_segs


def _get_veto_segs(cursor,veto_thresh,analyzed_segs,timeShift=False,trigXCentTimeData=None):
  """
  Create a veto segment list with a given KW significance threshold.
  Take an intersection with analysed segments so that all the veto segments
  stay in analysed segs.

  Changes: made much less reliant on SLOW SLOW SLOW database o_o --byuan 20110511
  """
  trigXdata_flag = 0
  if not trigXCentTimeData:
    print >> sys.stderr, "WARNING _get_veto_segs: no trigXCentTimeData, using old method"
    #print >> sys.stderr, "WARNING _get_veto_segs: no trigXCentTimeData, skipping and continuing"
    trigXdata_flag = 1
    return get_veto_segs(cursor,veto_thresh,analyzed_segs,timeShift)

  if trigXdata_flag == 0: # may be redundant, but just extra safety check
  	#if not trigXCentTimeData.has_key(0):
        #	timeShift = True
  	if timeShift:
    	    taus = unique(map(int,linspace(timeShiftMin,timeShiftMax,numTimeShifts)))
            taus = [t for t in taus if t != 0]
	    #taus = trigXCentTimeData.keys()  # probably a better method, but will evaluate
	    veto_seg_list = []
	    for tau in taus:
	      veto_times = []
	      if trigXCentTimeData.has_key(tau):
	      	for r, trigXCentTimes in trigXCentTimeData[tau].iteritems():
                        r = float(r)
                        if (isnan(r)):
                                r = 0.0
	        	if abs(r) >= veto_thresh:
	          		veto_times += trigXCentTimes
	      			veto_segs = segmentlist([bcvUtils.get_segment(t, opts.positive_window, opts.negative_window) for t in veto_times])
      	      			veto_seg_list.append((tau,veto_segs.coalesce() & analyzed_segs))
              	return veto_seg_list
	      else:
		print >> sys.stderr, "WARNING: key 'tau' does not exist...skipping...veto_seg_list empty, being returned..."
		return veto_seg_list
  	else:
		if trigXCentTimeData.has_key(0):
    			veto_times = []
    			for r, trigXCentTimes in trigXCentTimeData[0].iteritems():
                                r = float(r)
                                if (isnan(r)):
                                        r = 0.0
      				if abs(r) >= veto_thresh:
        				veto_times += trigXCentTimes
    					veto_segs = segmentlist([bcvUtils.get_segment(t, opts.positive_window, opts.negative_window) for t in veto_times])
				else:# hopefully this addition will help
					veto_segs = []
                	if veto_segs:  
    				return veto_segs.coalesce() & analyzed_segs
			else:
				return analyzed_segs
      		else:
			print >> sys.stderr, "WARNING trigXCentTimeData does not have key[0]...skipping, and returning analyzed_segs"
			return analyzed_segs

def injection_check(cur, injection_file, veto_segments, analyzed_segs, safety_thresh):
  """
  """
  all_injection_times = [float(time) for time in open(injection_file).readlines() if not time.startswith("#") and time != "\n"]

  injection_times = [t for t in all_injection_times if t in analyzed_segs]
  injection_times.sort()

  cur.execute("create table injections (GPSTime float, vetoed txt)")
  Nvetoed = 0
  for i in injection_times:
    try:
      i = float(i)
    except(ValueError):
      print >> sys.stderr, ("Error: --injection_file contains non-number.")
      raise
    if i in veto_segments:
      Nvetoed += 1
      cur.execute("insert into injections (GPSTime, vetoed) values (?,?)", (i,"Vetoed"))
    else:
      cur.execute("insert into injections (GPSTime, vetoed) values (?,?)", (i,"Not Vetoed"))

  totalInjNum = len(injection_times)
  if veto_segments:
 	Nexp = len(injection_times) * abs(veto_segments) / abs(analyzed_segs)
  else:
	Nexp = 0
  import scipy.stats
  prob = 1 - scipy.stats.poisson.cdf(Nvetoed - 1, Nexp)
  if prob > 10**safety_thresh or totalInjNum == 0 or prob != prob:
    safety = "Pass"
  else:
    safety = "Unsafe"

  return cur, Nvetoed, "%.4f"%Nexp, "%.2e"%prob, safety, totalInjNum


# =============================================================================
#
#                        Webpage Generation Functions
#
# =============================================================================


def channel_page(chan_name,info,channel_names):
  """
  create a webpage for each channel
  """
  
  ################## main html code for the report page ######################

  if info is None:
    contents = ["""
    <!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html
    4/strict.dtd">
    <html>
    <head>
    No analysis data produced by bcv_runscript.py
    </head>
    </html>
    """]    
    chan_page = open(baseDir+"/channel_pages/%s_%s-report_page.html"%(name_tag,chan_name),"w")
    chan_page.write("\n".join(contents))
    return
      
  if chan_name.split("+")[-1][3:] == "LINEAR":
    title = chan_name.split("+")[0]
    subtitle = "Linear Correlation"
  else:
    title = chan_name
    subtitle = "Bilinear Correlation" 
 
  contents = ["""
<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html
4/strict.dtd">
<html>
<head>
  <title>%s</title>
  <link rel="stylesheet" href="vstyle.css" type="text/css">
  <script type="text/javascript">
function toggleVisible(division) {
  if (document.getElementById("div_" + division).style.display == "none") {
    document.getElementById("div_" + division).style.display = "block";
    document.getElementById("input_" + division).checked = true;
  } else {
    document.getElementById("div_" + division).style.display = "none";
    document.getElementById("input_" + division).checked = false;
  } 
}
function gotoSection(section) {
  document.getElementById("div_" + section).style.display = "block";
  document.getElementById("input_" + section).checked = true;
  window.location.hash = section;
}
  </script>
</head>
  """%title]

  ## Index Box
  contents.append("""
<body>
<div class="title">
<h1> %s </h1>
</div>
<div class="index">
<h2>Index</h2>
<p>
<a href="javascript:gotoSection('Summary')">Summary</a><br>
<a href="javascript:gotoSection('%s')">%s</a><br>
<a href="javascript:gotoSection('Channel H Triggers')">Channel H Triggers</a><br>
<a href="../results/%s">Veto Segment List</a><br>
<a href="../results/%s">Text Summary</a><br>
<a href="../results/%s">Database Result</a><br>
<a href="../info/%s">Analyzed Segments</a><br>
<a href="../info/%s">.ini File</a><br>
<a href="../configs/%s">Configuration File</a><br>
<a href="../logs/%s">Log</a><br>
</p>
</div>
  """%(title,subtitle,subtitle,path_names["vetoSegmentFile"],path_names["txtSummary"],path_names["dbSummary"],path_names["segment_file"],path_names["ini_file"],path_names["config_file"],path_names["log_file"]))

  ## Summary Section  
  contents.append("""
<div class="content">
<!--summary-->
<a name="Summary"></a>
<h2 class="Summary"><input id="input_Summary" checked="checked"
 onclick="toggleVisible('Summary');" type="checkbox">Summary
</h2>
<div id="div_Summary" style="display: block;">
<a name="report"></a>
<br />
<div id="div_report" style="display: block;">
<center>
<table>
<tbody>
<tr><td><b>Veto Efficiency:</b></td>       <td>%.2f %%</td> <td>(%d H trigs in total)</td>
<tr><td><b>Dead Time:</b></td> <td> %.4f %%</td> <td>(%d s/ %d s)</td>
<tr><td><b>Veto Efficiency / Deadtime:</b></td>       <td>%.2f </td>
<tr><td><b>rThresh:</b></td>       <td>%.3f </td>
<tr><td><b>Accidental Veto Probability:</b></td> <td>%.2e</td>
<tr><td><b>Accidental Veto Rate (Hz):</b></td> <td>%.2e</td>
<tr><td><b>Veto Significance:</b></td> <td>%.2f</td>
<tr><td><b>Vetoed Inj / Total Inj:</b></td> <td>%s / %s</td>
<tr><td><b>Safety Probability:</b></td> <td>%s</td> </b></td> <td>(%s)</td>
</tbody>
</table>
</center>
</div>
  """%(info["vetoEfficiency"],info["numTrigsH"],info["deadTimePercentage"],info["deadTime"],info["analysisDuration"],info["efficiencyOverDeadtime"],info["rThresh"], info["accidentalVetoProb"],info["accidentalVetoRate"],info["vetoSignificance"],info["Nvetoed"],info["totalInjectionNumber"],info["safetyProbability"],info["safety"]))

  ## Time Shift Plot
  contents.append(plot_section(subtitle,\
	 ["%s_TimeShiftPlot"%chan_name, "%s_CrossCorrHist"%chan_name, "%s_ROC"%chan_name], \
 	["Time-shift Plot of the Correlation", \
	"Correlation Histograms", "Some Title"])) 
  
  contents.append(plot_section("Channel H Triggers",\
	 ["%s_TimeSignificPlot"%chan_name, "%s_TimeCentFreqPlot"%chan_name, "%s_CentFreqSignificPlot"%chan_name], \
 	["Trigger Significance Vs Central Time", \
	"Central Frequency Vs Central Time",\
	"Trigger Significance Vs Central Frequency"])) 
  
  ## Closing
  user=os.environ['USER']
  curTime=time.strftime('%m-%d-%Y %H:%M:%S',time.localtime())
  contents.append(""" 
</div>
<div class="footer">
Created by user %s on %s<br>
</div>
</body>
</html>
  """%(user,curTime))

  # write down
  chan_page = open(baseDir+"/channel_pages/%s_%s-report_page.html"%(name_tag,chan_name),"w")
  chan_page.write("\n".join(contents))

def plot_section(title, nameList, subtitleList):
  """
  Retuen html code for typical plot section.
  title: title of the section 
  name: name of the plot file without extension
  desctiption: description displayed above plot (optional)
  """
  name = title; 
  ps = ["""
<a name="%s"></a>
<h2 class="%s"><input id="input_%s"
 checked="checked" onclick="toggleVisible('%s');"
 type="checkbox">%s
</h2> 
<div id="div_%s" style="display: block;">
  """%(name,name,name,name,title,title)];

  for i in range(len(nameList)):
      name = nameList[i];
      ps.append("""
<a name="%s"></a>
<a id="a_%s_plot"
 href="../plots/%s.png"><img
 id="img_%s_plot"
 src="../plots/%s.thumb.png"
 alt="%s_plot"></a>
  """%(name,name,name,name,name,name))

  ps.append("""
<br>
</div>
""");

  ps = "".join(ps);
  return ps


# =============================================================================
#
#                          Set Up Directories for Webpages
#
# =============================================================================

def setup_dir(channel_info):
    """
    Gather necessary files if not in place already.
    Return file paths.
    
    """
    
    for d in ("plots","channel_pages","info","results","logs","configs"):
      d = os.path.join(baseDir,d)
      if not os.path.isdir(d):
        os.makedirs(d)
    
    if(channel_info==None):
      return None
    
    path_names = {}

    ## get style sheet for the html page
    vstyle_loc = 'inputfiles/vstyle.css'
    place_file(vstyle_loc,"channel_pages",ignore=False)
        
    ## get plots if not there already
    # make a list of plot files for this name_tag in each plot directory
    #plots = [f for f in glob.glob("%s/plots/*.png"%chan_dir)]
    #plots = [f for f in glob.glob("%s/plots/*.png"%chan_dir)]
    #for p in plots:
    #  src = os.path.abspath(p)
    #  place_file(src,"plots")
   
    ## get text summary
    src = channel_info['txtSummary']
    path_names["txtSummary"] = place_file(src,"results",prefix=chan_name)

    ## get db file
    src = channel_info['dbSummary']
    os.system("chmod 705 %s"%src)
    path_names["dbSummary"] = place_file(src,"results",prefix=chan_name)


    ## get veto segment file
    src = channel_info["vetoSegmentFile"]
    path_names["vetoSegmentFile"] = place_file(src,"results",prefix=chan_name)

    ## get segment file
    src = os.path.abspath(opts.segment_file)
    path_names["segment_file"] =  place_file(src,"info")
            
    ## get param file
    src = os.path.abspath(opts.ini_file)
    path_names["ini_file"] = place_file(src,"info")

    ## get configuration file
    src = os.path.abspath(channel_info["configurationFile"])
    path_names["config_file"] = place_file(src,"configs",prefix=chan_name)

    ## get log file
    # maybe combine with condor log file
    src = os.path.abspath(channel_info["logFile"])
    path_names["log_file"] = place_file(src,"logs",prefix=chan_name)

    return path_names

def place_file(src,dst,prefix=None,ignore=True):
  """
  Copy a file from src to dst, with checking of existence, and return the file
  name
  dst is one of "plots", "channel_pages", "info", "results", "logs", "configs",
  and will be combined with baseDir
  If prefix is given, it would be added to the file name
  If ignore is true, ignore when file cannot be copied, otherwise give an error
  """
  file_name = os.path.basename(src)
  if prefix is not None:
    file_name = prefix+"_"+file_name
  dst = os.path.join(baseDir,dst,file_name)
  if not os.path.isfile(dst):
    exitNum = os.system("cp %s %s"%(src,dst))
    if exitNum != 0:
      if ignore:
        print >>sys.stderr, "Warning: could not copy %s to %s, ignoring"%(src,dst)
      else:
        print >>sys.stderr, "Error: could not copy %s to %s."%(src,dst)
        sys.exit(1)
    
  return file_name

# =============================================================================
#
#                                  MAIN
# 
# =============================================================================

# performance testing for entire script
__start = time.time()

# parse commandline
opts = parse_commandline()

# access configuration file
cp = ConfigParser.ConfigParser()
cp.read(opts.ini_file)
name_tag = cp.get("general","tag")
original_tag = os.path.basename(opts.result_dir).split("-")[0]
timeShiftMin = cp.getint("data_conditioning","timeShiftMin")
timeShiftMax = cp.getint("data_conditioning","timeShiftMax")
numTimeShifts = cp.getint("data_conditioning","numTimeShifts")
warnings.filterwarnings("ignore")
# 
if opts.use_rMax:
  statistics = "rMax"
else:
  statistics = "r"

# create output directory if not exist
baseDir = os.path.join(opts.out_dir,'%s_webpage'%name_tag)
baseDir = os.path.abspath(baseDir)
if not os.path.isdir(baseDir):
  if opts.verbose:
    print >> sys.stderr, "creating output directory %s..."%baseDir
    os.makedirs(baseDir)

# get the absolute path of result directory
chan_dir = os.path.abspath(opts.result_dir)

if opts.verbose:
  print >> sys.stderr, "gathering infomation from %s..."%(chan_dir)

# Figure out channel name from directory name
# Assumption is that tag doesn't contain "-" (checked in veto_setup)
chan_file = os.path.basename(chan_dir)
chan_name = chan_file.split("-",2)[-1]


## get necessary info

# segment list used
analyzed_segs = bcvUtils.read_segfile(opts.segment_file)

## Load H KW trigs times
# We need centralTime, centralFreqency, SNR
# Read lines avoiding white space and comment lines, and transdpose
# cut by SNR cutoff
trigs = bcvUtils.textRead(opts.HTriggerFile)
SNRsH = array(trigs[4])
aboveThreshIdxH = SNRsH >= opts.SNRcutoffH

gpsTriggerHList = {}

gpsTriggerHList['centralTime'] = array(trigs[2])[aboveThreshIdxH]
gpsTriggerHList['centralFrequency'] = array(trigs[3])[aboveThreshIdxH]
gpsTriggerHList['triggerSignificance'] = SNRsH[aboveThreshIdxH]

del aboveThreshIdxH
del trigs

# get channel name responsible for KW triggers
# (for biliear, fast channel KW triggers are used to coincidence
if opts.couplingModel == "linear":
  single_chan_name = chan_name
else:
  single_chan_name = chan_name.split("+")[0]
 

# Load X KW trig number - for now: in the future just get it from calculation
# read lines avoiding white space and comment lines and count line number

Xtrigs = bcvUtils.textRead("%s/KWtrigs/%s_%s.txt"%(opts.base_dir, original_tag,single_chan_name))

if Xtrigs:
	SNRsX = array(Xtrigs[4])
	aboveThreshIdxX = SNRsX >= opts.SNRcutoffX
	numXTrigs = len(SNRsX[aboveThreshIdxX])
	del aboveThreshIdxX
else:
	numXTrigs = 0

#del aboveThreshIdxX
del Xtrigs

if opts.verbose:
  print >> sys.stderr, "Applying veto threshold..."
channel_info = applyVetoThreshold(chan_name,chan_dir,opts.reqAccVetoRate, gpsTriggerHList,numXTrigs,opts.scratch_dir,opts.verbose,opts.out_dir,opts.performance_test,opts.memdatabase,opts.standalone)

if opts.verbose:
  print >> sys.stderr, "Setting up the web directory..."
path_names = setup_dir(channel_info)
if opts.verbose:
  print >> sys.stderr, "Creating a web page..."
channel_page(chan_name,channel_info,path_names)

        
if opts.verbose: print >> sys.stderr, "%s done!"%__prog__

# performance testing for entire script
if opts.performance_test: 
  __elapsed = time.time() - __start
  print >> sys.stderr, "### Done in %s seconds ###"%__elapsed

